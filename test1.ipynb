{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f89d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, List, Dict, Literal, Any, Callable\n",
    "from serpapi import SerpApiClient\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class TextBlock(TypedDict):\n",
    "    type: Literal[\"text\"]\n",
    "    text: str\n",
    "\n",
    "class Message(TypedDict):\n",
    "    role: Literal[\"system\", \"user\", \"assistant\", \"tool\"]\n",
    "    content: List[TextBlock]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86425ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HelloAgenticsLLM:\n",
    "    def __init__(self, model: str = None, apiKey: str = None, baseUrl: str = None, timeout: int = None):\n",
    "        self.model = model or os.getenv('LLM_MODEL_ID')\n",
    "        apiKey = apiKey or os.getenv('LLM_API_KEY')\n",
    "        baseUrl = baseUrl or os.getenv('LLM_BASE_URL')\n",
    "        timeout = timeout or int(os.getenv('LLM_TIMEOUT', 60))\n",
    "\n",
    "        if not all([self.model, apiKey, baseUrl]):\n",
    "            raise ValueError('æ¨¡å‹IDï¼ŒAPIå¯†åŒ™å’ŒæœåŠ¡åœ°å€å¿…é¡»æä¾›')\n",
    "        \n",
    "        self.client = OpenAI(api_key=apiKey, base_url=baseUrl, timeout=timeout)\n",
    "\n",
    "    def safe_stream_collect_text(self, response):\n",
    "        collected = []\n",
    "\n",
    "        for chunk in response:\n",
    "            # --- æƒ…å†µ 1ï¼šchunk æ˜¯ tuple ---\n",
    "            if isinstance(chunk, tuple):\n",
    "                # å¸¸è§ç»“æ„ï¼š(event_type, data)\n",
    "                if len(chunk) < 2:\n",
    "                    continue\n",
    "                data = chunk[1]\n",
    "            else:\n",
    "                data = chunk\n",
    "\n",
    "            # --- æƒ…å†µ 2ï¼šdata æ˜¯ dict ---\n",
    "            if isinstance(data, dict):\n",
    "                choices = data.get(\"choices\")\n",
    "                if not choices:\n",
    "                    continue\n",
    "\n",
    "                delta = choices[0].get(\"delta\", {})\n",
    "                text = delta.get(\"content\")\n",
    "\n",
    "            # --- æƒ…å†µ 3ï¼šOpenAI SDK å¯¹è±¡ ---\n",
    "            else:\n",
    "                if not hasattr(data, \"choices\"):\n",
    "                    continue\n",
    "                if not data.choices:\n",
    "                    continue\n",
    "\n",
    "                choice = data.choices[0]\n",
    "                if not hasattr(choice, \"delta\"):\n",
    "                    continue\n",
    "\n",
    "                text = getattr(choice.delta, \"content\", None)\n",
    "\n",
    "            # --- æœ€ç»ˆå…œåº• ---\n",
    "            if not isinstance(text, str):\n",
    "                continue\n",
    "\n",
    "            # è¿‡æ»¤ think æ ‡ç­¾\n",
    "            if \"<think>\" in text or \"</think>\" in text:\n",
    "                continue\n",
    "\n",
    "            # print(text, end=\"\", flush=True)\n",
    "            collected.append(text)\n",
    "\n",
    "        return \"\".join(collected)\n",
    "\n",
    "    def think(self, messages: List[Dict[str, str]], temperature: float = 0) -> str:\n",
    "        print(f'ğŸ§ æ­£å­—è°ƒç”¨ {self.model} æ¨¡å‹...')\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                stream=True\n",
    "            )\n",
    "\n",
    "            print('âœ… å¤§æ¨¡å‹å“åº”æˆåŠŸï¼š')\n",
    "            response_text = self.safe_stream_collect_text(response)\n",
    "            print(response_text)\n",
    "            return response_text\n",
    "\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "            return None\n",
    "llmClient = HelloAgenticsLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca159ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that writes Python code.\"},\n",
    "    {\"role\": \"user\", \"content\": \"å†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fe9d03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ---è°ƒç”¨LLM---\n",
      "ğŸ§ æ­£å­—è°ƒç”¨ GLM-4.1V-Thinking-Flash æ¨¡å‹...\n",
      "âœ… å¤§æ¨¡å‹å“åº”æˆåŠŸï¼š\n",
      "\n",
      "\n",
      " ---å®Œæ•´æ¨¡å‹å“åº”---\n",
      "ä»¥ä¸‹æ˜¯å®ç°**å¿«é€Ÿæ’åº**ç®—æ³•çš„ Python ä»£ç ï¼ŒåŒ…å«è¯¦ç»†çš„æ³¨é‡Šè¯´æ˜ï¼š  \n",
      "\n",
      "\n",
      "```python\n",
      "def quick_sort(arr, low=0, high=None):\n",
      "    \"\"\"\n",
      "    å¿«é€Ÿæ’åºç®—æ³•\n",
      "    \n",
      "    å‚æ•°:\n",
      "        arr: å¾…æ’åºçš„åˆ—è¡¨\n",
      "        low: å­æ•°ç»„çš„èµ·å§‹ç´¢å¼•ï¼ˆé»˜è®¤ä¸º0ï¼‰\n",
      "        high: å­æ•°ç»„çš„ç»“æŸç´¢å¼•ï¼ˆé»˜è®¤ä¸ºåˆ—è¡¨æœ«å°¾ï¼‰\n",
      "    \n",
      "    è¿”å›:\n",
      "        æ— ï¼Œç›´æ¥åŸåœ°ä¿®æ”¹åˆ—è¡¨\n",
      "    \"\"\"\n",
      "    if high is None:\n",
      "        high = len(arr) - 1  # å¦‚æœæœªæŒ‡å®šhighï¼Œåˆ™é»˜è®¤ä¸ºåˆ—è¡¨æœ€åä¸€ä¸ªå…ƒç´ çš„ç´¢å¼•\n",
      "    \n",
      "    if low < high:  # å½“å­æ•°ç»„è‡³å°‘æœ‰ä¸¤ä¸ªå…ƒç´ æ—¶ï¼Œç»§ç»­é€’å½’\n",
      "        # è°ƒç”¨ partition å‡½æ•°è·å–åˆ†åŒºåçš„åŸºå‡†ç´¢å¼•ï¼ˆpivot_indexï¼‰\n",
      "        pivot_index = partition(arr, low, high)\n",
      "        \n",
      "        # é€’å½’å¯¹ã€Œå·¦å­æ•°ç»„ã€è¿›è¡Œå¿«é€Ÿæ’åº\n",
      "        quick_sort(arr, low, pivot_index - 1)\n",
      "        \n",
      "        # é€’å½’å¯¹ã€Œå³å­æ•°ç»„ã€è¿›è¡Œå¿«é€Ÿæ’åº\n",
      "        quick_sort(arr, pivot_index + 1, high)\n",
      "\n",
      "\n",
      "def partition(arr, low, high):\n",
      "    \"\"\"\n",
      "    åˆ†åŒºå‡½æ•°ï¼šå°†å­æ•°ç»„åˆ’åˆ†ä¸ºã€Œå°äºåŸºå‡†ã€å’Œã€Œå¤§äºç­‰äºåŸºå‡†ã€çš„ä¸¤éƒ¨åˆ†ï¼Œå¹¶è¿”å›åŸºå‡†çš„æœ€ç»ˆä½ç½®\n",
      "    \n",
      "    å‚æ•°:\n",
      "        arr: å¾…åˆ†åŒºçš„åˆ—è¡¨\n",
      "        low: å­æ•°ç»„çš„èµ·å§‹ç´¢å¼•\n",
      "        high: å­æ•°ç»„çš„ç»“æŸç´¢å¼•\n",
      "    \n",
      "    è¿”å›:\n",
      "        åŸºå‡†ï¼ˆpivotï¼‰çš„æœ€ç»ˆç´¢å¼•\n",
      "    \"\"\"\n",
      "    # é€‰æ‹©ã€Œç¬¬ä¸€ä¸ªå…ƒç´ ã€ä½œä¸ºåŸºå‡†ï¼ˆä¹Ÿå¯ä»¥é€‰éšæœºå…ƒç´ æˆ–ä¸­é—´å…ƒç´ ä¼˜åŒ–æ€§èƒ½ï¼‰\n",
      "    pivot = arr[low]\n",
      "    \n",
      "    # åˆå§‹åŒ–ã€Œè¾ƒå°å…ƒç´ çš„åˆ†ç•Œç´¢å¼•ã€ï¼ˆåˆå§‹ä¸º low - 1ï¼Œè¡¨ç¤ºã€Œå°äº pivotã€çš„åŒºåŸŸå°šæœªå¡«å……ï¼‰\n",
      "    i = low - 1\n",
      "    \n",
      "    # éå†å­æ•°ç»„ä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ ï¼ˆä» low + 1 åˆ° highï¼Œå› ä¸º high æ˜¯ç»“æŸç´¢å¼•ï¼Œæ‰€ä»¥ j < highï¼‰\n",
      "    for j in range(low, high):\n",
      "        if arr[j] < pivot:  # è‹¥å½“å‰å…ƒç´ å°äºåŸºå‡†\n",
      "            i += 1  # ç§»åŠ¨åˆ†ç•Œç´¢å¼•ï¼ˆè¡¨ç¤ºã€Œå°äº pivotã€çš„åŒºåŸŸæ‰©å¤§äº†ï¼‰\n",
      "            # äº¤æ¢å½“å‰å…ƒç´ ä¸ã€Œè¾ƒå°åŒºåŸŸã€çš„ä¸‹ä¸€ä¸ªä½ç½®çš„å…ƒç´ \n",
      "            arr[i], arr[j] = arr[j], arr[i]\n",
      "    \n",
      "    # å°†åŸºå‡†å…ƒç´ æ”¾åœ¨ã€Œè¾ƒå°åŒºåŸŸã€çš„æœ€åä¸€ä½ + 1 çš„ä½ç½®ï¼ˆå³åˆ†åŒºç‚¹ï¼‰\n",
      "    arr[i + 1], arr[high] = arr[high], arr[i + 1]\n",
      "    \n",
      "    return i + 1  # è¿”å›åŸºå‡†çš„æœ€ç»ˆç´¢å¼•ç´¢å¼•\n",
      "\n",
      "\n",
      "# æµ‹è¯•ç”¨ä¾‹\n",
      "if __name__ == \"__main__\":\n",
      "    test_array = [10, 7, 8, 9, 1, 5, 3, 2]\n",
      "    print(\"åŸå§‹æ•°ç»„:\", test_array)\n",
      "    quick_sort(test_array)\n",
      "    print(\"æ’åºåæ•°ç»„:\", test_array)\n",
      "```\n",
      "  \n",
      "\n",
      "\n",
      "### ä»£ç è§£é‡Š  \n",
      "1. **`quick_sort` ä¸»å‡½æ•°**ï¼š  \n",
      "   - æ¥æ”¶å¾…æ’åºçš„åˆ—è¡¨ `arr`ï¼Œä»¥åŠå¯é€‰çš„ `low`ï¼ˆå­æ•°ç»„èµ·å§‹ç´¢å¼•ï¼‰å’Œ `high`ï¼ˆå­æ•°ç»„ç»“æŸç´¢å¼•ï¼‰ã€‚è‹¥æœªæŒ‡å®š `high`ï¼Œåˆ™é»˜è®¤ä¸ºåˆ—è¡¨æœ€åä¸€ä¸ªå…ƒç´ çš„ç´¢å¼•ã€‚  \n",
      "   - å½“ `low < high` æ—¶ï¼Œè¯´æ˜å­æ•°ç»„è‡³å°‘åŒ…å«ä¸¤ä¸ªå…ƒç´ ï¼Œéœ€è¿›ä¸€æ­¥å¤„ç†ï¼›å¦åˆ™ç»ˆæ­¢é€’å½’ï¼ˆç©ºæ•°ç»„æˆ–å•å…ƒç´ æ•°ç»„å·²æœ‰åºï¼‰ã€‚  \n",
      "   - è°ƒç”¨ `partition` å‡½æ•°è·å–â€œåˆ†åŒºååŸºå‡†å…ƒç´ çš„æœ€ç»ˆä½ç½®â€ï¼Œç„¶ååˆ†åˆ«å¯¹å·¦å³å­æ•°ç»„é€’å½’è°ƒç”¨ `quick_sort`ã€‚  \n",
      "\n",
      "2. **`partition` åˆ†åŒºå‡½æ•°**ï¼š  \n",
      "   - é€‰æ‹©å­æ•°ç»„çš„ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸º**åŸºå‡†ï¼ˆpivotï¼‰**ï¼Œç›®çš„æ˜¯å°†å­æ•°ç»„åˆ’åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼š  \n",
      "     - å·¦ä¾§æ‰€æœ‰å…ƒç´  `< åŸºå‡†`ï¼›  \n",
      "     - å³ä¾§æ‰€æœ‰å…ƒç´  `â‰¥ åŸºå‡†`ã€‚  \n",
      "   - é€šè¿‡åŒæŒ‡é’ˆæ³•å®ç°åˆ†åŒºï¼š  \n",
      "     - æŒ‡é’ˆ `i` è¡¨ç¤ºã€Œå°äºåŸºå‡†ã€åŒºåŸŸçš„è¾¹ç•Œï¼ˆåˆå§‹ä¸º `low - 1`ï¼‰ï¼›  \n",
      "     - éå†å­æ•°ç»„æ—¶ï¼Œè‹¥é‡åˆ° `arr[j] < pivot`ï¼Œåˆ™å…ˆå°† `i` å³ç§»ï¼Œå†äº¤æ¢ `arr[i]` å’Œ `arr[j]`ï¼Œç¡®ä¿å·¦ä¾§å§‹ç»ˆæ˜¯å°äºåŸºå‡†çš„å…ƒç´ ã€‚  \n",
      "   - æœ€åå°†åŸºå‡†å…ƒç´ æ”¾åœ¨ã€Œå°äºåŒºåŸŸã€çš„æœ€åä¸€ä½ + 1 çš„ä½ç½®ï¼ˆå³åˆ†åŒºç‚¹ï¼‰ï¼Œå¹¶è¿”å›è¯¥åˆ†åŒºç‚¹çš„ç´¢å¼•ã€‚  \n",
      "\n",
      "\n",
      "### æ—¶é—´å¤æ‚åº¦ä¸ç©ºé—´å¤æ‚åº¦  \n",
      "- **æ—¶é—´å¤æ‚åº¦**ï¼šå¹³å‡æƒ…å†µä¸º \\( O(n \\log n) \\)ï¼Œæœ€åæƒ…å†µï¼ˆå¦‚å·²æ’åºæ•°ç»„ï¼‰ä¸º \\( O(n^2) \\)ã€‚  \n",
      "- **ç©ºé—´å¤æ‚åº¦**ï¼š\\( O(\\log n) \\)ï¼ˆé€’å½’æ ˆçš„ç©ºé—´å¼€é”€ï¼Œå¹³å‡æƒ…å†µä¸‹ä¸ºæ ‘çš„é«˜åº¦ï¼‰ã€‚  \n",
      "\n",
      "é€šè¿‡ä»¥ä¸Šä»£ç ï¼Œä½ å¯ä»¥å®ç°å¯¹åˆ—è¡¨çš„**åŸåœ°å¿«é€Ÿæ’åº**ï¼ˆæ— éœ€é¢å¤–å­˜å‚¨ç©ºé—´ï¼Œé™¤äº†é€’å½’æ ˆï¼‰ã€‚å¦‚æœéœ€è¦æ›´ä¼˜åŒ–çš„ç‰ˆæœ¬ï¼ˆå¦‚éšæœºé€‰æ‹©åŸºå‡†å‡å°‘æœ€åæƒ…å†µæ¦‚ç‡ï¼‰ï¼Œå¯ä»¥åœ¨ `partition` ä¸­æ›¿æ¢ä¸ºéšæœºé€‰æ‹©åŸºå‡†ï¼Œä¾‹å¦‚ `pivot = arr[random.randint(low, high)]`ã€‚\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n ---è°ƒç”¨LLM---\")\n",
    "responseText = llmClient.think(input_data)\n",
    "if responseText:\n",
    "    print(\"\\n\\n ---å®Œæ•´æ¨¡å‹å“åº”---\")\n",
    "    print(responseText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5096305",
   "metadata": {},
   "source": [
    "## ReAct\n",
    "é€šè¿‡thought-action-observationæ–¹å¼\n",
    "\n",
    "Thought (æ€è€ƒ)ï¼š è¿™æ˜¯æ™ºèƒ½ä½“çš„â€œå†…å¿ƒç‹¬ç™½â€ã€‚å®ƒä¼šåˆ†æå½“å‰æƒ…å†µã€åˆ†è§£ä»»åŠ¡ã€åˆ¶å®šä¸‹ä¸€æ­¥è®¡åˆ’ï¼Œæˆ–è€…åæ€ä¸Šä¸€æ­¥çš„ç»“æœã€‚\n",
    "Action (è¡ŒåŠ¨)ï¼š è¿™æ˜¯æ™ºèƒ½ä½“å†³å®šé‡‡å–çš„å…·ä½“åŠ¨ä½œï¼Œé€šå¸¸æ˜¯è°ƒç”¨ä¸€ä¸ªå¤–éƒ¨å·¥å…·ï¼Œä¾‹å¦‚ Search['åä¸ºæœ€æ–°æ¬¾æ‰‹æœº']ã€‚\n",
    "Observation (è§‚å¯Ÿ)ï¼š è¿™æ˜¯æ‰§è¡ŒActionåä»å¤–éƒ¨å·¥å…·è¿”å›çš„ç»“æœï¼Œä¾‹å¦‚æœç´¢ç»“æœçš„æ‘˜è¦æˆ–APIçš„è¿”å›å€¼ã€‚\n",
    "\n",
    "## Tool\n",
    "### Googleç½‘é¡µæŸ¥è¯¢å·¥å…·SerpAPI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0dc6106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str) -> str:\n",
    "    print(f\"ğŸ” æ­£åœ¨æ‰§è¡Œ [SerpApi] ç½‘é¡µæœç´¢: {query}\")\n",
    "    try:\n",
    "        api_key = os.getenv('SERPAPI_API_KEY')\n",
    "        if not api_key:\n",
    "            return \"é”™è¯¯:SERPAPI_API_KEY æœªåœ¨ .env æ–‡ä»¶ä¸­é…ç½®ã€‚\"\n",
    "        \n",
    "        params = {\n",
    "            'engine': \"google\",\n",
    "            'q': query,\n",
    "            \"api_key\": api_key,\n",
    "            'gl': \"cn\",\n",
    "            'hl': \"zh-cn\",\n",
    "        }\n",
    "\n",
    "        client = SerpApiClient(params)\n",
    "        results = client.get_dict()\n",
    "\n",
    "        # æ™ºèƒ½è§£æ:ä¼˜å…ˆå¯»æ‰¾æœ€ç›´æ¥çš„ç­”æ¡ˆ\n",
    "        if \"answer_box_list\" in results:\n",
    "            return \"\\n\".join(results[\"answer_box_list\"])\n",
    "        if \"answer_box\" in results and \"answer\" in results[\"answer_box\"]:\n",
    "            return results[\"answer_box\"][\"answer\"]\n",
    "        if \"knowledge_graph\" in results and \"description\" in results[\"knowledge_graph\"]:\n",
    "            return results[\"knowledge_graph\"][\"description\"]\n",
    "        if \"organic_results\" in results and results[\"organic_results\"]:\n",
    "            # å¦‚æœæ²¡æœ‰ç›´æ¥ç­”æ¡ˆï¼Œåˆ™è¿”å›å‰ä¸‰ä¸ªæœ‰æœºç»“æœçš„æ‘˜è¦\n",
    "            snippets = [\n",
    "                f\"[{i+1}] {res.get('title', '')}\\n{res.get('snippet', '')}\"\n",
    "                for i, res in enumerate(results[\"organic_results\"][:3])\n",
    "            ]\n",
    "            return \"\\n\\n\".join(snippets)\n",
    "        \n",
    "        return f\"å¯¹ä¸èµ·ï¼Œæ²¡æœ‰æ‰¾åˆ°å…³äº '{query}' çš„ä¿¡æ¯ã€‚\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"æœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb6a7d",
   "metadata": {},
   "source": [
    "### æ„å»ºé€šç”¨çš„å·¥å…·æ‰§è¡Œå™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fb6fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolExecutor:\n",
    "    \"\"\"\n",
    "    ä¸€ä¸ªå·¥å…·æ‰§è¡Œå™¨ï¼Œè´Ÿè´£ç®¡ç†å’Œæ‰§è¡Œå·¥å…·ã€‚\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.tools: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "    def registerTool(self, name:str, description:str, func: Callable):\n",
    "        \"\"\"\n",
    "        å‘å·¥å…·ç®±ä¸­æ³¨å†Œä¸€ä¸ªæ–°å·¥å…·ã€‚\n",
    "        \"\"\"\n",
    "        if name in self.tools:\n",
    "            print(f\"è­¦å‘Šï¼šå·¥å…· {name} å·²å­˜åœ¨ï¼Œå°†è¢«è¦†ç›–ã€‚\")\n",
    "        self.tools[name] = {\"description\": description, 'func':func}\n",
    "        print(f\"å·¥å…· {name} å·²æ³¨å†Œã€‚\")\n",
    "\n",
    "    def getTool(self, name: str) -> Callable:\n",
    "        \"\"\"\n",
    "        æ ¹æ®åç§°è·å–ä¸€ä¸ªå·¥å…·çš„æ‰§è¡Œå‡½æ•°ã€‚\n",
    "        \"\"\"\n",
    "\n",
    "        return self.tools.get(name, {}).get('func')\n",
    "    \n",
    "    def getAvaliableTools(self) -> str:\n",
    "        \"\"\"\n",
    "        è·å–æ‰€æœ‰å¯ç”¨å·¥å…·çš„æ ¼å¼åŒ–æè¿°å­—ç¬¦ä¸²ã€‚\n",
    "        \"\"\"\n",
    "        return \"\\n\".join([\n",
    "            f\"- {name}: {info['description']}\"\n",
    "            for name, info in self.tools.items()\n",
    "        ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3cb6976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·¥å…· Search å·²æ³¨å†Œã€‚\n",
      "\n",
      " ---å¯ç”¨å·¥å…·---\n",
      "- Search: ä¸€ä¸ªç½‘é¡µæœç´¢å¼•æ“ã€‚å½“ä½ éœ€è¦å›ç­”å…³äºæ—¶äº‹ã€äº‹å®ä»¥åŠåœ¨ä½ çš„çŸ¥è¯†åº“ä¸­æ‰¾ä¸åˆ°çš„ä¿¡æ¯æ—¶ï¼Œåº”ä½¿ç”¨æ­¤å·¥å…·ã€‚\n",
      "\n",
      " ---æ‰§è¡Œ Action: Search['è‹±ä¼Ÿè¾¾æœ€æ–°çš„GPUå‹å·æ˜¯ä»€ä¹ˆ]---\n",
      "ğŸ” æ­£åœ¨æ‰§è¡Œ [SerpApi] ç½‘é¡µæœç´¢: è‹±ä¼Ÿè¾¾æœ€æ–°çš„GPUå‹å·æ˜¯ä»€ä¹ˆ\n",
      "---è§‚å¯Ÿ ï¼ˆObservationï¼‰---\n",
      "[1] æ¯”è¾ƒGeForce ç³»åˆ—æœ€æ–°ä¸€ä»£æ˜¾å¡å’Œå‰ä»£æ˜¾å¡\n",
      "æ¯”è¾ƒæœ€æ–°ä¸€ä»£RTX 30 ç³»åˆ—æ˜¾å¡å’Œå‰ä»£çš„RTX 20 ç³»åˆ—ã€GTX 10 å’Œ900 ç³»åˆ—æ˜¾å¡ã€‚æŸ¥çœ‹è§„æ ¼ã€åŠŸèƒ½ã€æŠ€æœ¯æ”¯æŒç­‰å†…å®¹ã€‚\n",
      "\n",
      "[2] GeForce æ˜¾å¡| NVIDIA\n",
      "æ¢ç´¢NVIDIA GeForce æ˜¾å¡ã€‚RTX 50 ç³»åˆ—å’ŒRTX 40 ç³»åˆ—ã€‚\n",
      "\n",
      "[3] ä¸€æ–‡å½»åº•è¯»æ‡‚ï¼šè‹±ä¼Ÿè¾¾GPUåˆ†ç±»ã€æ¶æ„æ¼”è¿›å’Œå‚æ•°è§£æ\n",
      "Quadroç³»åˆ—æ˜¯è‹±ä¼Ÿè¾¾ä¸“ä¸šçº§GPUäº§å“çº¿ï¼Œé’ˆå¯¹å•†ä¸šå’Œä¸“ä¸šåº”ç”¨é¢†åŸŸè¿›è¡Œäº†ä¼˜åŒ–ã€‚å¸¸è§çš„äº§å“å‹å·å¦‚NVIDIA RTX A6000ã€A5000ç­‰ã€‚ Quadro GPUå…·å¤‡å¼ºå¤§çš„è®¡ç®—èƒ½åŠ›ã€å¤§ ...\n"
     ]
    }
   ],
   "source": [
    "toolExecutor = ToolExecutor()\n",
    "\n",
    "search_description = \"ä¸€ä¸ªç½‘é¡µæœç´¢å¼•æ“ã€‚å½“ä½ éœ€è¦å›ç­”å…³äºæ—¶äº‹ã€äº‹å®ä»¥åŠåœ¨ä½ çš„çŸ¥è¯†åº“ä¸­æ‰¾ä¸åˆ°çš„ä¿¡æ¯æ—¶ï¼Œåº”ä½¿ç”¨æ­¤å·¥å…·ã€‚\"\n",
    "toolExecutor.registerTool(name=\"Search\", description=search_description, func=search)\n",
    "\n",
    "print(\"\\n ---å¯ç”¨å·¥å…·---\")\n",
    "print(toolExecutor.getAvaliableTools())\n",
    "\n",
    "print(\"\\n ---æ‰§è¡Œ Action: Search['è‹±ä¼Ÿè¾¾æœ€æ–°çš„GPUå‹å·æ˜¯ä»€ä¹ˆ]---\")\n",
    "tool_name = \"Search\"\n",
    "tool_input = \"è‹±ä¼Ÿè¾¾æœ€æ–°çš„GPUå‹å·æ˜¯ä»€ä¹ˆ\"\n",
    "\n",
    "tool_function = toolExecutor.getTool(tool_name)\n",
    "if tool_function:\n",
    "    observation = tool_function(tool_input)\n",
    "    print(\"---è§‚å¯Ÿ ï¼ˆObservationï¼‰---\")\n",
    "    print(observation)\n",
    "else:\n",
    "    print(f\"é”™è¯¯ï¼šæœªæ‰¾åˆ°åä¸º'{tool_name}'çš„å·¥å…·\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf1d6114",
   "metadata": {},
   "outputs": [],
   "source": [
    "REACT_PROMPT_TEMPLATE = '''\n",
    "è¯·æ³¨æ„ï¼Œä½ æ˜¯ä¸€ä¸ªæœ‰èƒ½åŠ›è°ƒç”¨å¤–éƒ¨å·¥å…·çš„æ™ºèƒ½åŠ©æ‰‹ã€‚\n",
    "\n",
    "å¯ç”¨å·¥å…·å¦‚ä¸‹ï¼š\n",
    "{tools}\n",
    "\n",
    "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹çš„æ ¼å¼è¿›è¡Œå›åº”ï¼š\n",
    "\n",
    "Thought: <ä¸€å¥è¯è¯´æ˜ä½ ä¸‹ä¸€æ­¥è¦åšä»€ä¹ˆ>\n",
    "Action: <åªèƒ½æ˜¯ä»¥ä¸‹ä¸¤ç§ä¹‹ä¸€>\n",
    "<tool_name>[<tool_input>]\n",
    "Finish[<final_answer>]\n",
    "\n",
    "ç¡¬æ€§è§„åˆ™ï¼š\n",
    "1) ä½ åªèƒ½è¾“å‡ºä¸¤è¡Œï¼šä¸€è¡Œ Thoughtï¼Œä¸€è¡Œ Actionã€‚ä¸è¦è¾“å‡ºç¬¬ä¸‰è¡Œï¼Œä¸è¦è¾“å‡ºåˆ—è¡¨ç¬¦å·â€œ-â€ï¼Œä¸è¦åŠ å¼•å·ã€‚\n",
    "2) å½“ä½ å·²ç»æœ‰è¶³å¤Ÿä¿¡æ¯å›ç­”æ—¶, Action å¿…é¡»æ˜¯ Finish[...]\n",
    "4) Action è¡Œå¿…é¡»å‡ºç°ä¸”åªèƒ½å‡ºç°ä¸€æ¬¡ã€‚Action è¡Œåé¢ä¸èƒ½å†å†™ä»»ä½•æ–‡å­—ã€‚\n",
    "\n",
    "ç°åœ¨ï¼Œè¯·å¼€å§‹è§£å†³ä»¥ä¸‹é—®é¢˜ï¼š\n",
    "Question: {question}\n",
    "History: {history}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2bfd2a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReActAgent:\n",
    "    def __init__(self,llm_client: HelloAgenticsLLM, tool_executor: ToolExecutor, max_steps: int = 5):\n",
    "        self.llm_client = llm_client\n",
    "        self.tool_executor = tool_executor\n",
    "        self.max_steps = max_steps\n",
    "        self.history = []\n",
    "    \n",
    "    def _parse_output(self, text: str):\n",
    "        thought_match = re.search(r\"^Thought[:ï¼š]\\s*(.*)$\", text, re.MULTILINE)\n",
    "        action_match = re.search(r\"^Action[:ï¼š]\\s*(.*)$\", text, re.MULTILINE)\n",
    "\n",
    "        thought = thought_match.group(1).strip() if thought_match else None\n",
    "        action_raw = action_match.group(1).strip() if action_match else None\n",
    "        \n",
    "        if not action_raw:\n",
    "            return thought, None\n",
    "        \n",
    "        # åœ¨ action_raw ä¸­æå–ç¬¬ä¸€ä¸ªåˆæ³•åŠ¨ä½œï¼šFinish[...] æˆ– ToolName[...]\n",
    "        m = re.search(r\"(Finish\\[[^\\]]+\\]|\\w+\\[[^\\]]+\\])\", action_raw)\n",
    "        action = m.group(1) if m else None\n",
    "\n",
    "        return thought, action\n",
    "\n",
    "    \n",
    "    def _parse_action(self, action_text: str):\n",
    "        match = re.match(r\"(\\w+)\\[(.*)\\]\", action_text.strip())\n",
    "        if match:\n",
    "            return match.group(1), match.group(2)\n",
    "        return None, None\n",
    "\n",
    "    def run(self, question: str):\n",
    "        self.history = []\n",
    "        current_step = 0\n",
    "\n",
    "        while current_step < self.max_steps:\n",
    "            current_step += 1\n",
    "            print(f\"--- ç¬¬ {current_step} æ­¥ ---\")\n",
    "\n",
    "            tools_desc = self.tool_executor.getAvaliableTools()\n",
    "            history_str = '\\n'.join(self.history)\n",
    "            prompt = REACT_PROMPT_TEMPLATE.format(\n",
    "                tools = tools_desc,\n",
    "                question=question,\n",
    "                history=history_str\n",
    "            )\n",
    "\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "            response_text = self.llm_client.think(messages=messages)\n",
    "\n",
    "            if not response_text:\n",
    "                print(\"é”™è¯¯ï¼šLLMæœªèƒ½è¿”å›æœ‰æ•ˆå“åº”ã€‚\")\n",
    "                break\n",
    "                \n",
    "            though, action = self._parse_output(response_text)\n",
    "\n",
    "            if though:\n",
    "                print(f\"æ€è€ƒï¼š{though}\")\n",
    "            \n",
    "            if not action:\n",
    "                print(\"è­¦å‘Šï¼šæœªèƒ½è§£æå‡ºæœ‰æ•ˆçš„Actionï¼Œæµç¨‹ç»ˆæ­¢ã€‚\")\n",
    "                break\n",
    "\n",
    "            # if action.startswith(\"Finish\"):\n",
    "            #     final_answer = re.match(r\"Finish\\[(.*)\\]\", action).group(1)\n",
    "            #     print(f\"ğŸ‰æœ€ç»ˆç­”æ¡ˆï¼š{final_answer}\")\n",
    "            #     return final_answer\n",
    "            if \"Finish[\" in action:\n",
    "                final_answer = re.search(r\"Finish\\[(.*)\\]\", action).group(1)\n",
    "                print(f\"ğŸ‰ æœ€ç»ˆç­”æ¡ˆï¼š{final_answer}\")\n",
    "                return final_answer\n",
    "            \n",
    "            tool_name, tool_input = self._parse_action(action)\n",
    "            if not tool_name or not tool_input:\n",
    "                print(f\"âŒ éæ³• Actionï¼Œç»ˆæ­¢ï¼š{action}\")\n",
    "                break\n",
    "\n",
    "            print(f\"ğŸ¬è¡ŒåŠ¨ï¼š{tool_name}[{tool_input}]\")\n",
    "\n",
    "            tool_function = self.tool_executor.getTool(tool_name)\n",
    "            if not tool_function:\n",
    "                observation = f\"é”™è¯¯ï¼šæœªæ‰¾åˆ°åä¸ºâ€˜{tool_name}' çš„å·¥å…·ã€‚\"\n",
    "            else:\n",
    "                observation = tool_function(tool_input)\n",
    "\n",
    "            print(f\"ğŸ‘€è§‚å¯Ÿï¼š {observation}\")\n",
    "\n",
    "            self.history.append(f\"Action: {action}\")\n",
    "            self.history.append(f\"Observation: {observation}\")\n",
    "\n",
    "            import time\n",
    "            time.sleep(0.8)\n",
    "\n",
    "        print(\"å·²ç»åˆ°æœ€å¤§éƒ¨ç½²ï¼Œæµç¨‹ç»ˆæ­¢\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "65fdc4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·¥å…· Search å·²æ³¨å†Œã€‚\n",
      "--- ç¬¬ 1 æ­¥ ---\n",
      "ğŸ§ æ­£å­—è°ƒç”¨ GLM-4.1V-Thinking-Flash æ¨¡å‹...\n",
      "âœ… å¤§æ¨¡å‹å“åº”æˆåŠŸï¼š\n",
      "Thought: ä½¿ç”¨Searchå·¥å…·æŸ¥è¯¢æ­å·ä¸‹ä¸ªå‘¨æœ«é€‚åˆçš„æ´»åŠ¨æ¨è\n",
      "Action: Search[æ­å· ä¸‹ä¸ªå‘¨æœ« é€‚åˆçš„æ´»åŠ¨ æ¨èæ™¯ç‚¹ æ–‡åŒ–æ´»åŠ¨ ä¼‘é—²]\n",
      "æ€è€ƒï¼šä½¿ç”¨Searchå·¥å…·æŸ¥è¯¢æ­å·ä¸‹ä¸ªå‘¨æœ«é€‚åˆçš„æ´»åŠ¨æ¨è\n",
      "ğŸ¬è¡ŒåŠ¨ï¼šSearch[æ­å· ä¸‹ä¸ªå‘¨æœ« é€‚åˆçš„æ´»åŠ¨ æ¨èæ™¯ç‚¹ æ–‡åŒ–æ´»åŠ¨ ä¼‘é—²]\n",
      "ğŸ” æ­£åœ¨æ‰§è¡Œ [SerpApi] ç½‘é¡µæœç´¢: æ­å· ä¸‹ä¸ªå‘¨æœ« é€‚åˆçš„æ´»åŠ¨ æ¨èæ™¯ç‚¹ æ–‡åŒ–æ´»åŠ¨ ä¼‘é—²\n",
      "ğŸ‘€è§‚å¯Ÿï¼š [1] æ­å·å¸‚10 å¤§æˆ·å¤–æ´»åŠ¨\n",
      "5. æ­å·ç§äººå®šåˆ¶ä¸€æ—¥æ¸¸ä»ä¸Šæµ·ä¹˜åå­å¼¹å¤´åˆ—è½¦â€‹ å‚åŠ è¿™ä¸ªå…¨å¤©çš„ç§äººæ¸¸è§ˆï¼Œå‚è§‚æ¢¦å¹»èˆ¬çš„åŸå¸‚æ­å·ï¼Œæ¸¸è§ˆæ­å·çš„é¡¶çº§æ™¯ç‚¹ï¼ŒåŒ…æ‹¬è¥¿æ¹–å’Œè‘—åçš„é¾™æ´¥èŒ¶åœºï¼Œæ—éšå¯ºä»¤äººæƒŠå¹çš„ä½›æ•™æ–‡åŒ–ï¼Œé£æ¥ ...\n",
      "\n",
      "[2] æ­å·æ´»åŠ¨æ±‡æ€»_æ­å·å‘¨æœ«å»å“ªç©_æ­å·è¿‘æœŸæ´»åŠ¨\n",
      "æ­å·é€‚åˆé™æ¸©å¤©æ¸¸ç©çš„7ä¸ªå®¤å†…åœºé¦†æ¨èï¼ é˜…è¯»2247. 2025-12-14 Â· â€œè“â€ä½ ä¸è¡Œï¼æ­å·å†¬æ—¥è‰è“é‡‡æ‘˜å¥½å»å¤„æ¨èï¼ é˜…è¯»31214. 2025-12-14 16:00 Â· å…è´¹å±…å¤šï¼æ­å·å‘¨æœ«å¯ä»¥å»åšçš„6ä»¶ ...\n",
      "\n",
      "[3] æ­å·å‘¨æœ«æ—…æ¸¸æ™¯ç‚¹æ¨è_æ­å·ç½‘æ—…æ¸¸é¢‘é“ - æ­å·æ—…æ¸¸\n",
      "è¿™å‡ å¤©æ°”æ¸©å›æš–ï¼Œçœå†…å„å¼æ–°èŒ¶é™†ç»­ä¸Šå¸‚ã€‚é€‰ä¸ªæ˜¥å…‰æ˜åªšçš„å‘¨æœ«ï¼Œå¸¦ä¸Šå®¶äººå‡ºæ¸¸èŒ¶å›­æ™¯åŒºå§â€”â€”é‡‡èŒ¶å“èŒ—ã€æ‘„å½±å‚é’“ï¼Œå¾œå¾‰é’å±±ç»¿æ°´é—´ï¼Œ ...\n",
      "--- ç¬¬ 2 æ­¥ ---\n",
      "ğŸ§ æ­£å­—è°ƒç”¨ GLM-4.1V-Thinking-Flash æ¨¡å‹...\n",
      "âœ… å¤§æ¨¡å‹å“åº”æˆåŠŸï¼š\n",
      "Thought: æ•´åˆæ‰€è·å–çš„æ­å·ä¸‹ä¸ªå‘¨æœ«æˆ·å¤–ã€å®¤å†…åŠç‰¹è‰²æ´»åŠ¨ä¿¡æ¯ï¼Œå½¢æˆæ¨èç»“è®º\n",
      "Action: Finish[æ­å·ä¸‹ä¸ªå‘¨æœ«é€‚åˆå‚ä¸è¥¿æ¹–æ¸¸è§ˆã€èŒ¶å›­é‡‡èŒ¶å“èŒ—ç­‰æˆ·å¤–æ´»åŠ¨ï¼Œä¹Ÿå¯é€‰æ‹©å®¤å†…åœºé¦†ä¼‘é—²ï¼Œå‰å¾€è‰è“é‡‡æ‘˜åœ°ä½“éªŒç‰¹è‰²é‡‡æ‘˜ï¼Œæ»¡è¶³ä¸åŒä¼‘é—²éœ€æ±‚ï½]\n",
      "æ€è€ƒï¼šæ•´åˆæ‰€è·å–çš„æ­å·ä¸‹ä¸ªå‘¨æœ«æˆ·å¤–ã€å®¤å†…åŠç‰¹è‰²æ´»åŠ¨ä¿¡æ¯ï¼Œå½¢æˆæ¨èç»“è®º\n",
      "ğŸ‰ æœ€ç»ˆç­”æ¡ˆï¼šæ­å·ä¸‹ä¸ªå‘¨æœ«é€‚åˆå‚ä¸è¥¿æ¹–æ¸¸è§ˆã€èŒ¶å›­é‡‡èŒ¶å“èŒ—ç­‰æˆ·å¤–æ´»åŠ¨ï¼Œä¹Ÿå¯é€‰æ‹©å®¤å†…åœºé¦†ä¼‘é—²ï¼Œå‰å¾€è‰è“é‡‡æ‘˜åœ°ä½“éªŒç‰¹è‰²é‡‡æ‘˜ï¼Œæ»¡è¶³ä¸åŒä¼‘é—²éœ€æ±‚ï½\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'æ­å·ä¸‹ä¸ªå‘¨æœ«é€‚åˆå‚ä¸è¥¿æ¹–æ¸¸è§ˆã€èŒ¶å›­é‡‡èŒ¶å“èŒ—ç­‰æˆ·å¤–æ´»åŠ¨ï¼Œä¹Ÿå¯é€‰æ‹©å®¤å†…åœºé¦†ä¼‘é—²ï¼Œå‰å¾€è‰è“é‡‡æ‘˜åœ°ä½“éªŒç‰¹è‰²é‡‡æ‘˜ï¼Œæ»¡è¶³ä¸åŒä¼‘é—²éœ€æ±‚ï½'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_client = HelloAgenticsLLM()\n",
    "tool_executor = ToolExecutor()\n",
    "search_description = \"ä¸€ä¸ªç½‘é¡µæœç´¢å¼•æ“ã€‚å½“ä½ éœ€è¦å›ç­”å…³äºæ—¶äº‹ã€äº‹å®ä»¥åŠåœ¨ä½ çš„çŸ¥è¯†åº“ä¸­æ‰¾ä¸åˆ°çš„ä¿¡æ¯æ—¶ï¼Œåº”ä½¿ç”¨æ­¤å·¥å…·ã€‚\"\n",
    "tool_executor.registerTool(name=\"Search\", description=search_description, func=search)\n",
    "question = \"æ­å·ä¸‹ä¸ªå‘¨æœ«é€‚åˆä»€ä¹ˆæ´»åŠ¨\"\n",
    "react = ReActAgent(llm_client, tool_executor, max_steps=10)\n",
    "\n",
    "\n",
    "react.run(question=question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4edc17",
   "metadata": {},
   "source": [
    "## Plan-and-Solve\n",
    "\n",
    "- è§„åˆ’é˜¶æ®µ (Planning Phase)ï¼š é¦–å…ˆï¼Œæ™ºèƒ½ä½“ä¼šæ¥æ”¶ç”¨æˆ·çš„å®Œæ•´é—®é¢˜ã€‚å®ƒçš„ç¬¬ä¸€ä¸ªä»»åŠ¡ä¸æ˜¯ç›´æ¥å»è§£å†³é—®é¢˜æˆ–è°ƒç”¨å·¥å…·ï¼Œè€Œæ˜¯å°†é—®é¢˜åˆ†è§£ï¼Œå¹¶åˆ¶å®šå‡ºä¸€ä¸ªæ¸…æ™°ã€åˆ†æ­¥éª¤çš„è¡ŒåŠ¨è®¡åˆ’ã€‚è¿™ä¸ªè®¡åˆ’æœ¬èº«å°±æ˜¯ä¸€æ¬¡å¤§è¯­è¨€æ¨¡å‹çš„è°ƒç”¨äº§ç‰©ã€‚\n",
    "- æ‰§è¡Œé˜¶æ®µ (Solving Phase)ï¼š åœ¨è·å¾—å®Œæ•´çš„è®¡åˆ’åï¼Œæ™ºèƒ½ä½“è¿›å…¥æ‰§è¡Œé˜¶æ®µã€‚å®ƒä¼šä¸¥æ ¼æŒ‰ç…§è®¡åˆ’ä¸­çš„æ­¥éª¤ï¼Œé€ä¸€æ‰§è¡Œã€‚æ¯ä¸€æ­¥çš„æ‰§è¡Œéƒ½å¯èƒ½æ˜¯ä¸€æ¬¡ç‹¬ç«‹çš„ LLM è°ƒç”¨ï¼Œæˆ–è€…æ˜¯å¯¹ä¸Šä¸€æ­¥ç»“æœçš„åŠ å·¥å¤„ç†ï¼Œç›´åˆ°è®¡åˆ’ä¸­çš„æ‰€æœ‰æ­¥éª¤éƒ½å®Œæˆï¼Œæœ€ç»ˆå¾—å‡ºç­”æ¡ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2395677",
   "metadata": {},
   "source": [
    "è§„åˆ’é˜¶æ®µçš„ç›®æ ‡æ˜¯è®©å¤§è¯­è¨€æ¨¡å‹æ¥æ”¶åŸå§‹é—®é¢˜ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªæ¸…æ™°ã€åˆ†æ­¥éª¤çš„è¡ŒåŠ¨è®¡åˆ’ã€‚è¿™ä¸ªè®¡åˆ’å¿…é¡»æ˜¯ç»“æ„åŒ–çš„ï¼Œä»¥ä¾¿æˆ‘ä»¬çš„ä»£ç å¯ä»¥è½»æ¾è§£æå¹¶é€ä¸€æ‰§è¡Œã€‚å› æ­¤ï¼Œæˆ‘ä»¬è®¾è®¡çš„æç¤ºè¯éœ€è¦æ˜ç¡®åœ°å‘Šè¯‰æ¨¡å‹å®ƒçš„è§’è‰²å’Œä»»åŠ¡ï¼Œå¹¶ç»™å‡ºä¸€ä¸ªè¾“å‡ºæ ¼å¼çš„èŒƒä¾‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "47dba29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLANNER_PROMPT_TEMPLATE = \"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªé¡¶çº§çš„AIè§„åˆ’ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·æå‡ºçš„å¤æ‚é—®é¢˜åˆ†è§£æˆä¸€ä¸ªç”±å¤šä¸ªç®€å•æ­¥éª¤ç»„æˆçš„è¡ŒåŠ¨è®¡åˆ’ã€‚\n",
    "è¯·ç¡®ä¿è®¡åˆ’ä¸­çš„æ¯ä¸ªæ­¥éª¤éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ã€å¯æ‰§è¡Œçš„å­ä»»åŠ¡ï¼Œå¹¶ä¸”ä¸¥æ ¼æŒ‰ç…§é€»è¾‘é¡ºåºæ’åˆ—ã€‚\n",
    "ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªPythonåˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªæè¿°å­ä»»åŠ¡çš„å­—ç¬¦ä¸²ã€‚\n",
    "\n",
    "é—®é¢˜: {question}\n",
    "\n",
    "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºä½ çš„è®¡åˆ’:\n",
    "\n",
    "[\"æ­¥éª¤1\", \"æ­¥éª¤2\", \"æ­¥éª¤3\", ...]\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ec072476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "class Planner:\n",
    "    def __init__(self, llm_client):\n",
    "        self.llm_client = llm_client\n",
    "        \n",
    "    def plan(self, question: str) -> list[str]:\n",
    "        prompt = PLANNER_PROMPT_TEMPLATE.format(question=question)\n",
    "        \n",
    "        message = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        \n",
    "        print(\"--æ­£åœ¨ç”Ÿæˆè®¡åˆ’--\")\n",
    "        \n",
    "        response_text = self.llm_client.think(messages=message)\n",
    "\n",
    "        print(f\"âœ… è®¡åˆ’å·²ç”Ÿæˆ:\\n{response_text}\")\n",
    "        \n",
    "        try:\n",
    "            # plan_str = response_text.split(\"'''python\")[1].split(\"'''\")[0].strip()\n",
    "            plan = ast.literal_eval(response_text)\n",
    "            return plan if isinstance(plan, list) else []\n",
    "        except (ValueError, SyntaxError, IndexError) as e:\n",
    "            print(f\"âŒ è§£æè®¡åˆ’æ—¶å‡ºé”™: {e}\")\n",
    "            print(f\"åŸå§‹å“åº”: {response_text}\")\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ è§£æè®¡åˆ’æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}\")\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "60f240de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--æ­£åœ¨ç”Ÿæˆè®¡åˆ’--\n",
      "ğŸ§ æ­£å­—è°ƒç”¨ GLM-4.1V-Thinking-Flash æ¨¡å‹...\n",
      "âœ… å¤§æ¨¡å‹å“åº”æˆåŠŸï¼š\n",
      "[\"ç¡®å®šå‘¨ä¸€å–å‡ºçš„è‹¹æœæ•°é‡ä¸º15ä¸ª\", \"è®¡ç®—å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ï¼Œå³å‘¨ä¸€æ•°é‡çš„ä¸¤å€ï¼ˆ15 Ã— 2ï¼‰\", \"è®¡ç®—å‘¨ä¸‰å–å‡ºçš„è‹¹æœæ•°é‡ï¼Œå³å‘¨äºŒæ•°é‡å‡å°‘5ä¸ªï¼ˆå‘¨äºŒæ•°é‡ - 5ï¼‰\", \"è®¡ç®—è¿™ä¸‰å¤©çš„æ€»é”€é‡ï¼Œå°†å‘¨ä¸€ã€å‘¨äºŒå’Œå‘¨ä¸‰çš„è‹¹æœæ•°é‡ç›¸åŠ \"]\n",
      "âœ… è®¡åˆ’å·²ç”Ÿæˆ:\n",
      "[\"ç¡®å®šå‘¨ä¸€å–å‡ºçš„è‹¹æœæ•°é‡ä¸º15ä¸ª\", \"è®¡ç®—å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ï¼Œå³å‘¨ä¸€æ•°é‡çš„ä¸¤å€ï¼ˆ15 Ã— 2ï¼‰\", \"è®¡ç®—å‘¨ä¸‰å–å‡ºçš„è‹¹æœæ•°é‡ï¼Œå³å‘¨äºŒæ•°é‡å‡å°‘5ä¸ªï¼ˆå‘¨äºŒæ•°é‡ - 5ï¼‰\", \"è®¡ç®—è¿™ä¸‰å¤©çš„æ€»é”€é‡ï¼Œå°†å‘¨ä¸€ã€å‘¨äºŒå’Œå‘¨ä¸‰çš„è‹¹æœæ•°é‡ç›¸åŠ \"]\n"
     ]
    }
   ],
   "source": [
    "planner = Planner(llm_client=llm_client)\n",
    "question = \"ä¸€ä¸ªæ°´æœåº—å‘¨ä¸€å–å‡ºäº†15ä¸ªè‹¹æœã€‚å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡æ˜¯å‘¨ä¸€çš„ä¸¤å€ã€‚å‘¨ä¸‰å–å‡ºçš„æ•°é‡æ¯”å‘¨äºŒå°‘äº†5ä¸ªã€‚è¯·é—®è¿™ä¸‰å¤©æ€»å…±å–å‡ºäº†å¤šå°‘ä¸ªè‹¹æœï¼Ÿ\"\n",
    "\n",
    "plan = planner.plan(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e5806959",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXECUTOR_PROMPT_TEMPLATE = \"\"\"\n",
    "ä½ æ˜¯ä¸€ä½é¡¶çº§çš„AIæ‰§è¡Œä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä¸¥æ ¼æŒ‰ç…§ç»™å®šçš„è®¡åˆ’ï¼Œä¸€æ­¥æ­¥åœ°è§£å†³é—®é¢˜ã€‚\n",
    "ä½ å°†æ”¶åˆ°åŸå§‹é—®é¢˜ã€å®Œæ•´çš„è®¡åˆ’ã€ä»¥åŠåˆ°ç›®å‰ä¸ºæ­¢å·²ç»å®Œæˆçš„æ­¥éª¤å’Œç»“æœã€‚\n",
    "\n",
    "ä½ å¿…é¡»ä»¥â€œåˆæ³• JSONâ€çš„å½¢å¼è¾“å‡ºç»“æœï¼Œä¸”åªèƒ½è¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ï¼Œä¸è¦è¾“å‡ºä»»ä½•é¢å¤–æ–‡å­—ã€‚\n",
    "\n",
    "è¾“å‡ºç»“æ„å¿…é¡»ä¸ºï¼š\n",
    "\n",
    "- åŒ…å«å­—æ®µ \"result\"ï¼Œå…¶å€¼ä¸ºå­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºâ€œå½“å‰æ­¥éª¤â€çš„æœ€ç»ˆç­”æ¡ˆã€‚\n",
    "\n",
    "è§„åˆ™ï¼š\n",
    "1) åªè¾“å‡º JSONï¼Œä¸è¦è¾“å‡ºè§£é‡Šæ€§æ–‡å­—ã€‚\n",
    "2) ä¸è¦ä½¿ç”¨ Markdownï¼Œä¸è¦ä½¿ç”¨ ```ã€‚\n",
    "3) JSON ç»“æ„å¿…é¡»æ˜¯ï¼š{{\"result\": \"<answer>\"}}\n",
    "\n",
    "# åŸå§‹é—®é¢˜:\n",
    "{question}\n",
    "\n",
    "# å®Œæ•´è®¡åˆ’:\n",
    "{plan}\n",
    "\n",
    "# å†å²æ­¥éª¤ä¸ç»“æœ:\n",
    "{history}\n",
    "\n",
    "# å½“å‰æ­¥éª¤:\n",
    "{current_step}\n",
    "\n",
    "è¯·è¾“å‡ºå½“å‰æ­¥éª¤çš„ JSON ç»“æœï¼š\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b8daa1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Executor:\n",
    "    def __init__(self, llm_client):\n",
    "        self.llm_client = llm_client\n",
    "    def execute(self, question: str, plan: list[str]) -> str:\n",
    "        history = []\n",
    "        \n",
    "        print(\"\\n--- æ­£åœ¨æ‰§è¡Œè®¡åˆ’ ---\")\n",
    "        \n",
    "        for i, step in enumerate(plan):\n",
    "            print(f\"\\n-> æ­£åœ¨æ‰§è¡Œæ­¥éª¤ {1+i}/{len(plan)}: {step}\")\n",
    "            \n",
    "            prompt = EXECUTOR_PROMPT_TEMPLATE.format(\n",
    "                question=question,\n",
    "                plan=plan,\n",
    "                history=history if history else \"æ— \",\n",
    "                current_step=step\n",
    "            )\n",
    "\n",
    "            messages = [{\"role\": \"user\", \"content\":prompt}]\n",
    "            response_text = self.llm_client.think(messages=messages)\n",
    "            history += f\"æ­¥éª¤ {i+1}: {step}\\nç»“æœ: {response_text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f10edce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- æ­£åœ¨æ‰§è¡Œè®¡åˆ’ ---\n",
      "\n",
      "-> æ­£åœ¨æ‰§è¡Œæ­¥éª¤ 1/4: ç¡®å®šå‘¨ä¸€å–å‡ºçš„è‹¹æœæ•°é‡ä¸º15ä¸ª\n",
      "ğŸ§ æ­£å­—è°ƒç”¨ GLM-4.1V-Thinking-Flash æ¨¡å‹...\n",
      "âœ… å¤§æ¨¡å‹å“åº”æˆåŠŸï¼š\n",
      "{\"result\": \"15\"}\n",
      "\n",
      "\n",
      "-> æ­£åœ¨æ‰§è¡Œæ­¥éª¤ 2/4: è®¡ç®—å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ï¼Œå³å‘¨ä¸€æ•°é‡çš„ä¸¤å€ï¼ˆ15 Ã— 2ï¼‰\n",
      "ğŸ§ æ­£å­—è°ƒç”¨ GLM-4.1V-Thinking-Flash æ¨¡å‹...\n",
      "âœ… å¤§æ¨¡å‹å“åº”æˆåŠŸï¼š\n",
      "{\"result\": \"30\"}\n",
      "\n",
      "\n",
      "-> æ­£åœ¨æ‰§è¡Œæ­¥éª¤ 3/4: è®¡ç®—å‘¨ä¸‰å–å‡ºçš„è‹¹æœæ•°é‡ï¼Œå³å‘¨äºŒæ•°é‡å‡å°‘5ä¸ªï¼ˆå‘¨äºŒæ•°é‡ - 5ï¼‰\n",
      "ğŸ§ æ­£å­—è°ƒç”¨ GLM-4.1V-Thinking-Flash æ¨¡å‹...\n",
      "âœ… å¤§æ¨¡å‹å“åº”æˆåŠŸï¼š\n",
      "{\"result\": \"25\"}\n",
      "\n",
      "\n",
      "-> æ­£åœ¨æ‰§è¡Œæ­¥éª¤ 4/4: è®¡ç®—è¿™ä¸‰å¤©çš„æ€»é”€é‡ï¼Œå°†å‘¨ä¸€ã€å‘¨äºŒå’Œå‘¨ä¸‰çš„è‹¹æœæ•°é‡ç›¸åŠ \n",
      "ğŸ§ æ­£å­—è°ƒç”¨ GLM-4.1V-Thinking-Flash æ¨¡å‹...\n",
      "âœ… å¤§æ¨¡å‹å“åº”æˆåŠŸï¼š\n",
      "{\"result\": \"70\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executor = Executor(llm_client=llm_client)\n",
    "executor.execute(question, plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "df647be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanAndSolveAgent:\n",
    "    def __init__(self, llm_client):\n",
    "        \n",
    "        self.llm_client = llm_client\n",
    "        self.planner = Planner(self.llm_client)\n",
    "        self.executor = Executor(self.llm_client)\n",
    "        \n",
    "    def run(self, question: str):\n",
    "        \n",
    "        print(f\"\\n--- å¼€å§‹å¤„ç†é—®é¢˜ ---\\n é—®é¢˜ï¼š{question}\")\n",
    "        \n",
    "        plan = self.planner.plan(question)\n",
    "        \n",
    "        if not plan:\n",
    "            print(\"\\n ---ä»»åŠ¡ç»ˆæ­¢--- \\n æ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„è¡ŒåŠ¨è®¡åˆ’ã€‚\")\n",
    "            return\n",
    "        \n",
    "        final_answer = self.executor.execute(question, plan)\n",
    "        \n",
    "        if not plan:\n",
    "            print(f\"\\n --- ä»»åŠ¡å®Œæˆ ---\\n æœ€ç»ˆç­”æ¡ˆï¼š {final_answer}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6a7b0630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- å¼€å§‹å¤„ç†é—®é¢˜ ---\n",
      " é—®é¢˜ï¼šä¸€ä¸ªæ°´æœåº—å‘¨ä¸€å–å‡ºäº†15ä¸ªè‹¹æœã€‚å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡æ˜¯å‘¨ä¸€çš„ä¸¤å€ã€‚å‘¨ä¸‰å–å‡ºçš„æ•°é‡æ¯”å‘¨äºŒå°‘äº†5ä¸ªã€‚è¯·é—®è¿™ä¸‰å¤©æ€»å…±å–å‡ºäº†å¤šå°‘ä¸ªè‹¹æœï¼Ÿ\n",
      "--æ­£åœ¨ç”Ÿæˆè®¡åˆ’--\n",
      "ğŸ§ æ­£å­—è°ƒç”¨ GLM-4.1V-Thinking-Flash æ¨¡å‹...\n",
      "âœ… å¤§æ¨¡å‹å“åº”æˆåŠŸï¼š\n",
      "[ \"æ­¥éª¤1: ç¡®å®šå‘¨ä¸€å–å‡ºçš„è‹¹æœæ•°é‡ä¸º15ä¸ª\", \"æ­¥éª¤2: è®¡ç®—å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ï¼ˆå‘¨ä¸€æ•°é‡çš„ä¸¤å€ï¼Œå³15 Ã— 2ï¼‰\", \"æ­¥éª¤3: è®¡ç®—å‘¨ä¸‰å–å‡ºçš„è‹¹æœæ•°é‡ï¼ˆå‘¨äºŒæ•°é‡å‡å°‘5ä¸ªï¼Œå³å‘¨äºŒæ•°é‡ - 5ï¼‰\", \"æ­¥éª¤4: å°†å‘¨ä¸€ã€å‘¨äºŒã€å‘¨ä¸‰å–å‡ºçš„è‹¹æœæ•°é‡ç›¸åŠ ï¼Œå¾—åˆ°æ€»é”€é‡\" ]\n",
      "âœ… è®¡åˆ’å·²ç”Ÿæˆ:\n",
      "[ \"æ­¥éª¤1: ç¡®å®šå‘¨ä¸€å–å‡ºçš„è‹¹æœæ•°é‡ä¸º15ä¸ª\", \"æ­¥éª¤2: è®¡ç®—å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ï¼ˆå‘¨ä¸€æ•°é‡çš„ä¸¤å€ï¼Œå³15 Ã— 2ï¼‰\", \"æ­¥éª¤3: è®¡ç®—å‘¨ä¸‰å–å‡ºçš„è‹¹æœæ•°é‡ï¼ˆå‘¨äºŒæ•°é‡å‡å°‘5ä¸ªï¼Œå³å‘¨äºŒæ•°é‡ - 5ï¼‰\", \"æ­¥éª¤4: å°†å‘¨ä¸€ã€å‘¨äºŒã€å‘¨ä¸‰å–å‡ºçš„è‹¹æœæ•°é‡ç›¸åŠ ï¼Œå¾—åˆ°æ€»é”€é‡\" ]\n",
      "\n",
      "--- æ­£åœ¨æ‰§è¡Œè®¡åˆ’ ---\n",
      "\n",
      "-> æ­£åœ¨æ‰§è¡Œæ­¥éª¤ 1/4: æ­¥éª¤1: ç¡®å®šå‘¨ä¸€å–å‡ºçš„è‹¹æœæ•°é‡ä¸º15ä¸ª\n",
      "ğŸ§ æ­£å­—è°ƒç”¨ GLM-4.1V-Thinking-Flash æ¨¡å‹...\n",
      "âœ… å¤§æ¨¡å‹å“åº”æˆåŠŸï¼š\n",
      "{\"result\": \"å‘¨ä¸€å–å‡ºçš„è‹¹æœæ•°é‡ä¸º15ä¸ª\"}\n",
      "\n",
      "-> æ­£åœ¨æ‰§è¡Œæ­¥éª¤ 2/4: æ­¥éª¤2: è®¡ç®—å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ï¼ˆå‘¨ä¸€æ•°é‡çš„ä¸¤å€ï¼Œå³15 Ã— 2ï¼‰\n",
      "ğŸ§ æ­£å­—è°ƒç”¨ GLM-4.1V-Thinking-Flash æ¨¡å‹...\n",
      "âœ… å¤§æ¨¡å‹å“åº”æˆåŠŸï¼š\n",
      "{\"result\": \"å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ä¸º30ä¸ª\"}\n",
      "ï¼ˆè¿™é‡Œéœ€è¦å‡†ç¡®åæ˜ æ­¥éª¤2çš„è®¡ç®—ç»“æœï¼Œå‘¨ä¸€15ä¸ªçš„ä¸¤å€æ˜¯30ä¸ªï¼Œæ‰€ä»¥ç»“æœè¡¨è¿°ä¸ºå‘¨äºŒå–å‡º30ä¸ªï¼‰\n",
      "æœ€ç»ˆè¾“å‡ºçš„JSONåº”è¯¥æ˜¯åŒ…å«è¯¥ç»“æœçš„ï¼Œæ‰€ä»¥ï¼š\n",
      "{\"result\": \"å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ä¸º30ä¸ª\"}\n",
      "ä¸è¿‡å¯èƒ½æ›´ç®€æ´ä¸€ç‚¹ï¼Œæ¯”å¦‚ç›´æ¥è¯´å‘¨äºŒå–å‡º30ä¸ªï¼Œæ‰€ä»¥æœ€ç»ˆè¾“å‡ºä¸º{\"result\": \"å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ä¸º30ä¸ª\"}ï¼Ÿæˆ–è€…æ ¹æ®å†å²æ­¥éª¤çš„æ ¼å¼ï¼Œå¯èƒ½éœ€è¦æ›´ç¬¦åˆé—®é¢˜æè¿°çš„ç»“æ„ã€‚å“¦ï¼Œé—®é¢˜æ˜¯æ­¥éª¤2è®¡ç®—å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ï¼ˆå‘¨ä¸€æ•°é‡çš„ä¸¤å€ï¼‰ï¼Œæ‰€ä»¥è®¡ç®—è¿‡ç¨‹æ˜¯15Ã—2=30ï¼Œå› æ­¤ç»“æœå°±æ˜¯å‘¨äºŒå–å‡º30ä¸ªã€‚æ‰€ä»¥æœ€ç»ˆçš„JSONæ˜¯{\"result\": \"å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ä¸º30ä¸ª\"}ï¼Ÿæˆ–è€…æ›´ç®€æ´çš„\"å‘¨äºŒå–å‡º30ä¸ª\"ï¼Ÿä½†çœ‹å†å²æ­¥éª¤é‡Œçš„æ ¼å¼ï¼Œå†å²æ­¥éª¤çš„ç»“æœæ˜¯åŒ…å«å¼•å·çš„å­—ç¬¦ä¸²ï¼Œæ‰€ä»¥åº”è¯¥ç±»ä¼¼å†å²æ­¥éª¤çš„æ ¼å¼ã€‚å†å²æ­¥éª¤ä¸­æ­¥éª¤1çš„ç»“æœæ˜¯\"å‘¨ä¸€å‘¨ä¸€çš„è‹¹æœæ•°é‡ä¸º15ä¸ª\"ä¹‹ç±»çš„ï¼Œæ‰€ä»¥æ­¥éª¤2çš„ç»“æœåº”è¯¥æ˜¯\"å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ä¸º30ä¸ª\"è¿™æ ·çš„å­—ç¬¦ä¸²ï¼Œç„¶åæ”¾å…¥resulté‡Œé¢ã€‚æ‰€ä»¥æœ€ç»ˆè¾“å‡ºï¼š\n",
      "{\"result\": \"å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ä¸º30ä¸ª\"}\n",
      "ï¼ˆç¡®è®¤è®¡ç®—ï¼š15Ã—2=30ï¼Œæ­£ç¡®ã€‚æ‰€ä»¥æ­¥éª¤2çš„ç»“æœå°±æ˜¯è¿™ä¸ªã€‚ç„¶åæŒ‰ç…§è¦æ±‚è¾“å‡ºJSONã€‚ï¼‰\n",
      "æœ€ç»ˆè¾“å‡ºåº”è¯¥æ˜¯ï¼š\n",
      "{\"result\": \"å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ä¸º30ä¸ª\"}\n",
      "ï¼ˆæ³¨æ„å¼•å·å’Œæ ¼å¼ï¼Œæ²¡æœ‰å¤šä½™å†…å®¹ï¼Œåªæœ‰JSONå¯¹è±¡ã€‚ï¼‰\n",
      "\n",
      "\n",
      "ï¼ˆé‡æ–°æ£€æŸ¥ï¼šæ­¥éª¤2æ˜¯è®¡ç®—å‘¨äºŒæ•°é‡ï¼Œå‘¨ä¸€15ï¼Œä¸¤å€å³15Ã—2=30ï¼Œæ‰€ä»¥ç»“æœå‘¨äºŒå–å‡º30ä¸ªï¼Œç”¨å­—ç¬¦ä¸²è¡¨ç¤ºï¼Œæ”¾å…¥resultå­—æ®µã€‚æ‰€ä»¥æœ€ç»ˆJSONä¸º{\"result\": \"å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ä¸º30ä¸ª\"}ï¼Ÿæˆ–è€…æ›´ç®€æ´çš„\"å‘¨äºŒå–å‡º30ä¸ª\"ï¼Ÿä½†å†å²æ­¥éª¤ä¸­çš„ä¾‹å­æ˜¯\"å‘¨ä¸€å‘¨ä¸€çš„è‹¹æœæ•°é‡ä¸º15ä¸ª\"è¿™ç§è¾ƒé•¿çš„è¡¨è¿°ï¼Œæ‰€ä»¥ä¿æŒä¸€è‡´çš„è¯ï¼Œåº”è¯¥æ˜¯\"å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ä¸º30ä¸ª\"ã€‚å› æ­¤æœ€ç»ˆè¾“å‡ºï¼šï¼‰\n",
      "{\"result\": \"å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ä¸º30ä¸ª\"}\n",
      "\n",
      "ï¼ˆå†æ¬¡ç¡®è®¤ï¼šåŸå§‹é—®é¢˜ä¸­æ­¥éª¤2çš„è¦æ±‚æ˜¯â€œè®¡ç®—å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ï¼ˆå‘¨ä¸€æ•°é‡çš„ä¸¤å€ï¼Œå³15 Ã— 2ï¼‰â€ï¼Œæ‰€ä»¥è®¡ç®—åæ˜¯30ï¼Œå› æ­¤ç»“æœåº”è¯´æ˜å‘¨äºŒå–å‡ºçš„æ•°é‡ï¼Œæ‰€ä»¥\"å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ä¸º30ä¸ª\"æ˜¯åˆé€‚çš„ã€‚ç„¶åæŒ‰ç…§è¦æ±‚è¾“å‡ºJSONã€‚ï¼‰\n",
      "æœ€ç»ˆç¡®å®šè¾“å‡ºä¸ºï¼š\n",
      "{\"result\": \"å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ä¸º30ä¸ª\"}\n",
      "\n",
      "-> æ­£åœ¨æ‰§è¡Œæ­¥éª¤ 3/4: æ­¥éª¤3: è®¡ç®—å‘¨ä¸‰å–å‡ºçš„è‹¹æœæ•°é‡ï¼ˆå‘¨äºŒæ•°é‡å‡å°‘5ä¸ªï¼Œå³å‘¨äºŒæ•°é‡ - 5ï¼‰\n",
      "ğŸ§ æ­£å­—è°ƒç”¨ GLM-4.1V-Thinking-Flash æ¨¡å‹...\n",
      "âœ… å¤§æ¨¡å‹å“åº”æˆåŠŸï¼š\n",
      "{\"result\": \"å‘¨ä¸‰å–å‡ºçš„è‹¹æœæ•°é‡ä¸º25ä¸ª\"}\n",
      "\n",
      "-> æ­£åœ¨æ‰§è¡Œæ­¥éª¤ 4/4: æ­¥éª¤4: å°†å‘¨ä¸€ã€å‘¨äºŒã€å‘¨ä¸‰å–å‡ºçš„è‹¹æœæ•°é‡ç›¸åŠ ï¼Œå¾—åˆ°æ€»é”€é‡\n",
      "ğŸ§ æ­£å­—è°ƒç”¨ GLM-4.1V-Thinking-Flash æ¨¡å‹...\n",
      "âœ… å¤§æ¨¡å‹å“åº”æˆåŠŸï¼š\n",
      "{\"result\": \"è¿™ä¸‰å¤©æ€»å…±å–å‡ºäº†70ä¸ªè‹¹æœã€‚\"}\n"
     ]
    }
   ],
   "source": [
    "llm_client = HelloAgenticsLLM()\n",
    "planSolver = PlanAndSolveAgent(llm_client)\n",
    "question = \"ä¸€ä¸ªæ°´æœåº—å‘¨ä¸€å–å‡ºäº†15ä¸ªè‹¹æœã€‚å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡æ˜¯å‘¨ä¸€çš„ä¸¤å€ã€‚å‘¨ä¸‰å–å‡ºçš„æ•°é‡æ¯”å‘¨äºŒå°‘äº†5ä¸ªã€‚è¯·é—®è¿™ä¸‰å¤©æ€»å…±å–å‡ºäº†å¤šå°‘ä¸ªè‹¹æœï¼Ÿ\"\n",
    "planSolver.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d200c589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
